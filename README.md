# Notes on Deep Learning
An online reference I update as I continue to grow my deep learning skills.
![](https://media.giphy.com/media/MoYC1N4nv7Fcs/giphy.gif)


## Recurrent Neural Networks (RNN) 
RNNs are designed to handle sequences of information. Situating an input within the context of a sequence allows the RNN to utilize context to better identify patterns in the data. These sequences can be of a time series nature (e.g. stills from a video feed), but need not be. Examples include sequences of letters or words, item IDs within a shopping cart, etc. 


<div align="center">
<img src="https://github.com/b-knight/Notes-on-Deep-Learning/blob/master/RNN.gif" align="middle" width="740" height="385" />
</div>



## References
### Recurrent Neural Networks & LSTM

- Karpathy, Andrej. [MachineLearner]. (2016, June 14th). *CS231n Lecture 10 - Recurrent Neural Networks, Image Captioning, LSTM*. Retrieved from https://www.youtube.com/watch?v=iX5V1WpxxkY.

- Nguyá»…n, Giang. (2013, March 10th). *7 - 5 - Long-term Short-term-memory*. Retrieved from https://www.youtube.com/watch?v=izGl1YSH_JA.

- Olah, Chris. (2015, August 27th). *Understanding LSTM Networks*. Retrieved from http://colah.github.io/posts/2015-08-Understanding-LSTMs/.
